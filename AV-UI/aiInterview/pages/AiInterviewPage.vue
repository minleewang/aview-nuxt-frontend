<template>
  <v-container v-if="!start" align="center">
    <div class="interview-container">
      <v-icon>mdi-account-tie</v-icon><br />
      <div v-html="startMessage"></div>
      <v-btn color="primary" @click="handleStartInterview">ë©´ì ‘ ì‹œì‘</v-btn>
    </div>
  </v-container>

  <v-container v-else fluid class="pa-0">
    <!-- ê°ì‹¸ëŠ” divì— 75% ê³ ì • -->
    <div style="width: 75%; margin: 0 auto">
      <v-row class="video-row" no-gutters style="margin: 0; padding: 0">
        <!-- ë©´ì ‘ê´€ -->
        <v-col
          cols="6"
          class="pa-0"
          style="display: flex; justify-content: flex-end"
        >
          <div class="video-box" style="width: 100%; height: 300px">
            <img
              :src="hhImage"
              alt="ë©´ì ‘ê´€"
              class="interviewer-image"
              style="width: 100%; height: 100%; object-fit: cover"
            />
          </div>
        </v-col>

        <!-- ê°€ìš´ë° ì—¬ë°± -->
        <v-col class="pa-0" style="max-width: 16px"></v-col>

        <!-- ë©´ì ‘ì -->
        <v-col
          cols="6"
          class="pa-0"
          style="display: flex; justify-content: flex-start"
        >
          <div class="video-box" style="width: 100%; height: 300px">
            <video
              ref="userVideo"
              autoplay
              playsinline
              muted
              class="user-video"
              style="width: 100%; height: 100%; object-fit: cover"
            ></video>
          </div>
        </v-col>
      </v-row>
    </div>

    <!-- ê°€ìš´ë° ì—¬ë°± -->
    <v-col class="pa-0" style="max-width: 16px"></v-col>
    <!-- âœ… ì§ˆë¬¸ ë©”ì‹œì§€/ë‹µë³€ ì˜ì—­ì„ ì˜ìƒ ë°”ë¡œ ì•„ë˜ë¡œ -->
    <v-col
      cols="12"
      class="pa-0 mt-4"
      style="display: flex; justify-content: center"
    >
      <div
        v-if="visible"
        class="interview-container"
        style="margin-top: 0; width: 75%"
      >
        <v-icon>mdi-account-tie</v-icon><br />
        <div v-html="startMessage"></div>
      </div>
      <div v-else class="interview-container" style="margin-top: 0; width: 75%">
        <v-icon>mdi-account-tie</v-icon><br />
        <h2 v-html="formattedAIMessage"></h2>
        <br />
        <div :class="{ timer: true, 'red-text': remainingTime <= 10 }">
          ë‚¨ì€ ì‹œê°„: {{ Math.floor(remainingTime / 60) }}:{{
            (remainingTime % 60).toString().padStart(2, "0")
          }}
        </div>
      </div>
    </v-col>
    <!-- âœ… ë¡œë”© ë©”ì‹œì§€ -->
    <div v-if="isLoading && !finished" class="message ai">
      <br />
      <p><strong>ë‹¤ìŒ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.</strong></p>
      <v-icon>mdi-account-tie</v-icon>
      <div class="loading-message">
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
      </div>
    </div>

    <!-- âœ… ë‹µë³€ ì…ë ¥ ë²„íŠ¼ -->
    <v-container v-if="start && !visible" class="input-area">
      <div class="button-group">
        <button class="send-button" @click="startSTT" :disabled="recognizing">
          ë§í•˜ê¸°
        </button>
        <button @click="replayQuestion">ğŸ—£ AI ì§ˆë¬¸ ë“£ê¸°</button>
      </div>
      <v-btn color="primary" @click="onAnswerComplete">ë‹µë³€ ì™„ë£Œ</v-btn>
      <div v-if="sttLog !== ''" class="stt-log">
        <p><strong>STT ê²°ê³¼:</strong> {{ sttLog }}</p>
      </div>
    </v-container>
  </v-container>
</template>
<script setup>
import { ref, computed, onMounted, onBeforeUnmount } from "vue";
import { useAiInterviewStore } from "../../aiInterview/stores/aiInterviewStore";
import { useRouter, onBeforeRouteLeave } from "vue-router";
import "@mdi/font/css/materialdesignicons.css";

const questionQueue = ref([]); // ì—¬ëŸ¬ ì§ˆë¬¸ ë‹´ê¸°
const currentQuestionIndex = ref(0); // í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤
const router = useRouter();
const aiInterviewStore = useAiInterviewStore();

const start = ref(false);
const visible = ref(true);
const isLoading = ref(false);
const finished = ref(false);
const recognizing = ref(false);
const sttLog = ref("");
const currentAIMessage = ref("");
const currentQuestionId = ref(1);
const currentInterviewId = ref(null);
const remainingTime = ref(90);
const timer = ref(null);
const maxQuestionId = ref(10); // ì•¼ì•¼ì•¼ì•¼ ë„ˆëŠ” ìˆ«ì ë­ê°€ì¢‹ë‹ˆ? ìµœëŒ€ìˆ«ìë¥¼ ì„¤ì •í•´ë³´ì
const startMessage = ref("");
const userVideo = ref(null);

let recognition;
const synth = process.client ? window.speechSynthesis : null;
let currentUtteance = null;

onMounted(() => {
  if (process.client) {
    speakStartMessage();

    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.continuous = false;
    recognition.interimResults = false;

    recognition.onstart = () => (recognizing.value = true);
    recognition.onend = () => (recognizing.value = false);
    recognition.onerror = () => (recognizing.value = false);
    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript;
      sttLog.value = transcript;
    };

    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
      if (userVideo.value) userVideo.value.srcObject = stream;
    });

    window.addEventListener("beforeunload", handleBeforeUnload);
  }
});

const speakStartMessage = () => {
  startMessage.value = `
    <br>
    <strong>
      <span>AI ëª¨ì˜ ë©´ì ‘ì´ ê³§ ì‹œì‘ë©ë‹ˆë‹¤.</span><br>
      <span>ë©´ì ‘ ì§ˆë¬¸ì´ í™”ë©´ì— í‘œì‹œë˜ë©°, ìë™ìœ¼ë¡œ ìŒì„±ìœ¼ë¡œ ì½ì–´ë“œë¦½ë‹ˆë‹¤.</span><br>
      <span>ì§ˆë¬¸ì„ ë‹¤ ë“¤ì€ ë’¤, <mark>ë§í•˜ê¸° ë²„íŠ¼</mark>ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”.</span><br>
      <span>ë§ˆì´í¬ì™€ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.</span>
    </strong>
  `;
};

const formattedAIMessage = computed(() => {
  return currentAIMessage.value.replace(/([.?])/g, "$1<br>");
});

const replayQuestion = () => {
  if (synth.speaking) synth.cancel();
  const utterance = new SpeechSynthesisUtterance(currentAIMessage.value);
  utterance.lang = "ko-KR";
  utterance.rate = 0.85;
  utterance.pitch = 1.0;
  setTimeout(() => synth.speak(utterance), 100);
};

const handleBeforeUnload = (event) => {
  if (start.value) {
    event.preventDefault();
    event.returnValue = "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?";
  }
};

const speakCurrentMessage = () => {
  clearInterval(timer.value);
  remainingTime.value = 90;
  currentUtteance = new SpeechSynthesisUtterance(currentAIMessage.value);
  currentUtteance.lang = "ko-KR";
  currentUtteance.rate = 0.85;
  currentUtteance.pitch = 1.0;
  currentUtteance.onend = () => {
    startTimer();
  };
  synth.speak(currentUtteance);
};

const showStartMessage = () => {
  visible.value = false;
  speakCurrentMessage();
};

const startTimer = () => {
  clearInterval(timer.value);
  timer.value = setInterval(() => {
    if (remainingTime.value > 0) {
      remainingTime.value--;
    } else {
      clearInterval(timer.value);
      onAnswerComplete();
    }
  }, 1000);
};

const startSTT = () => {
  if (recognition && !recognizing.value) recognition.start();
};

const handleStartInterview = async () => {
  const info = JSON.parse(localStorage.getItem("interviewInfo") || "{}");
  if (!info.tech || !info.exp) {
    alert("ë©´ì ‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.");
    router.push("/ai-interview");
    return;
  }

  start.value = true;
  const techSkillNumberList = info.skills;

  const res = await aiInterviewStore.requestCreateInterviewToDjango({
    userToken: localStorage.getItem("userToken"),
    jobCategory: info.tech,
    experienceLevel: info.exp,
    academicBackground: info.academic,
    projectExperience: info.project,
    interviewTechStack: techSkillNumberList,
  });

  currentInterviewId.value = Number(res.interviewId);
  currentAIMessage.value = res.question;

  const message = `AI ëª¨ì˜ ë©´ì ‘ì´ ê³§ ì‹œì‘ë©ë‹ˆë‹¤. ë©´ì ‘ ì§ˆë¬¸ì´ í™”ë©´ì— í‘œì‹œë˜ë©°, ìë™ìœ¼ë¡œ ìŒì„±ìœ¼ë¡œ ì½ì–´ë“œë¦½ë‹ˆë‹¤.
  ì§ˆë¬¸ì„ ë‹¤ ë“¤ì€ ë’¤ì— ë§í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”.
  ë§ˆì´í¬ì™€ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.`;

  const utterance = new SpeechSynthesisUtterance(message);
  utterance.lang = "ko-KR";
  utterance.rate = 1;
  utterance.pitch = 1;
  utterance.onend = () => {
    showStartMessage();
  };

  window.speechSynthesis.cancel();
  window.speechSynthesis.speak(utterance);
};

const onAnswerComplete = async () => {
  if (!sttLog.value.trim()) {
    alert("ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.");
    return;
  }
  // ğŸ” ìµœëŒ€ì§ˆë¬¸ ê°¯ìˆ˜ ì¡°ì •
  if (currentQuestionId.value >= maxQuestionId.value) {
    alert("ëª¨ë“  ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤");
    finished.value = true;
    return;
  }

  const info = JSON.parse(localStorage.getItem("interviewInfo") || "{}");

  const payload = {
    userToken: localStorage.getItem("userToken"),
    interviewId: currentInterviewId.value,
    questionId: currentQuestionId.value,
    answerText: sttLog.value,
    jobCategory: info.tech,
    experienceLevel: info.exp,
    academicBackground: info.academic,
    projectExperience: info.project,
    interviewTechStack: info.skills,
  };

  // ğŸ”„ ë‹µë³€ ì €ì¥
  await aiInterviewStore.requestCreateAnswerToDjango(payload);

  let nextQuestion = null; // âœ… ê³µí†µ ë³€ìˆ˜ ì„ ì–¸

  // ì§ˆë¬¸ íë¦„ì— ë”°ë¥¸ ë¶„ê¸°
  if (currentQuestionId.value === 1 || currentQuestionId.value === 2) {
    const followUp = await aiInterviewStore.requestFollowUpQuestionToDjango(
      payload
    );
    nextQuestion = followUp?.questions?.[0];
  } else if (currentQuestionId.value === 3) {
    const projectMain =
      await aiInterviewStore.requestProjectCreateInterviewToDjango(payload);
    nextQuestion = projectMain?.question?.[0];
  } else if (currentQuestionId.value === 4 || currentQuestionId.value === 5) {
    const projectFollowUp =
      await aiInterviewStore.requestProjectFollowUpQuestionToDjango(payload);
    nextQuestion = projectFollowUp?.questions?.[0];
  } else {
    alert("ëª¨ë“  ë©´ì ‘ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
    finished.value = true;
    router.push("/ai-interview/result");
    return;
  }

  if (!nextQuestion) {
    alert("ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    return;
  }

  currentQuestionId.value += 1;
  currentAIMessage.value = nextQuestion;
  sttLog.value = "";
  speakCurrentMessage();
};

onBeforeUnmount(() => {
  if (synth && synth.speaking) synth.cancel();
  localStorage.removeItem("interviewInfo");
  clearInterval(timer.value);
  window.removeEventListener("beforeunload", handleBeforeUnload);
});

onBeforeRouteLeave((to, from, next) => {
  if (start.value) {
    const answer = window.confirm(
      "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?"
    );
    if (answer) {
      clearInterval(timer.value);
      next();
    } else {
      next(false);
    }
  } else {
    next();
  }
});

useHead({
  title: `AI ëª¨ì˜ë©´ì ‘ & ì¸ì„±ë©´ì ‘ | `,
  meta: [
    {
      name: "description",
      content: "AI ëª¨ì˜ë©´ì ‘, AI ì¸ì„±ë©´ì ‘ ğŸ¯AIVì—ì„œ í™•ì¸í•´ë³´ì„¸ìš”.",
    },
    {
      hid: "keywords",
      name: "keywords",
      content:
        "ëª¨ì˜ë©´ì ‘, ai ëª¨ì˜ë©´ì ‘, ì¸ì„±ë©´ì ‘, ai ì¸ì„±ë©´ì ‘, ì¸ì ì„± ê²€ì‚¬ ì¤€ë¹„, ai ì¸ì , ai ë©´ì ‘, aim ëª¨ì˜ë©´ì ‘, aim ai ëª¨ì˜ë©´ì ‘, AIV ëª¨ì˜ë©´ì ‘, AIV, AIV, AIV, AIV Sniper",
    },
  ],
});
</script>

<style scoped>
.interview-container {
  margin-top: 20%;
  border: 1px solid #333;
  padding: 16px;
  border-radius: 10px;
  width: 70%;
}

.input-area {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 20px;
  width: 50%;
  margin-bottom: 0;
}

.send-button {
  padding: 10px 12px;
  background-color: black;
  color: white;
  border: none;
  border-radius: 20px;
  cursor: pointer;
  font-size: 16px;
}

.video-row {
  margin-top: 24px;
  margin-bottom: 24px;
}

.video-box {
  width: 100%;
  aspect-ratio: 4 / 3;
  border: 2px solid #ccc;
  border-radius: 12px;
  overflow: hidden;
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #000;
}

.interviewer-image {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.user-video {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

@keyframes loading-animation {
  0%,
  80%,
  100% {
    opacity: 0;
  }
  40% {
    opacity: 1;
  }
}

.context-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
.context-menu li {
  padding: 10px;
  cursor: pointer;
}
.context-menu li:hover {
  background-color: #f0f0f0;
}
</style>
