<template>
  <v-container v-if="!start" align="center">
    <div class="interview-container">
      <v-icon>mdi-account-tie</v-icon><br />
      <div v-html="startMessage"></div>
      <v-btn color="primary" @click="handleStartInterview">ë©´ì ‘ ì‹œì‘</v-btn>
    </div>
  </v-container>

  <v-container v-if="start" align="center">
    <div v-if="visible" class="interview-container">
      <v-icon>mdi-account-tie</v-icon><br />
      <div v-html="startMessage"></div>
    </div>

    <div v-if="!visible" class="interview-container">
      <v-icon>mdi-account-tie</v-icon><br />
      <h2 v-html="formattedAIMessage"></h2>
      <br />
      <div :class="{ timer: true, 'red-text': remainingTime <= 10 }">
        ë‚¨ì€ ì‹œê°„: {{ Math.floor(remainingTime / 60) }}:{{
          (remainingTime % 60).toString().padStart(2, "0")
        }}
      </div>
    </div>

    <div v-if="isLoading && !finished" class="message ai">
      <br />
      <p><strong>ë‹¤ìŒ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.</strong></p>
      <v-icon>mdi:account-tie</v-icon>
      <div class="loading-message">
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
      </div>
    </div>

    <v-container v-if="start && !visible" class="input-area">
      <div class="button-group">
        <button class="send-button" @click="startSTT" :disabled="recognizing">
          ë§í•˜ê¸°
        </button>
        <button @click="replayQuestion">ğŸ—£ AI ì§ˆë¬¸ ë“£ê¸°</button>
      </div>
      <v-btn color="primary" @click="onAnswerComplete">ë‹µë³€ ì™„ë£Œ</v-btn>
      <div v-if="sttLog !== ''" class="stt-log">
        <p><strong>STT ê²°ê³¼:</strong> {{ sttLog }}</p>
      </div>
    </v-container>
  </v-container>
</template>

<script setup>
import { ref, computed, onMounted, onBeforeUnmount } from "vue";
import { useAiInterviewStore } from "../../aiInterview/stores/aiInterviewStore"; // Pinia store import
import { useRouter, useRoute, onBeforeRouteLeave } from "vue-router";
import "@mdi/font/css/materialdesignicons.css";

const router = useRouter();
const aiInterviewStore = useAiInterviewStore();

const start = ref(false);
const visible = ref(true);
const isLoading = ref(false); // ë¡œë”© ìƒíƒœ ì¶”ê°€
const finished = ref(false);
const recognizing = ref(false);
const sttLog = ref("");
const currentAIMessage = ref(""); // í˜„ì¬ AI ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” ë³€ìˆ˜
const currentQuestionId = ref(1);
const currentInterviewId = ref(null);
const remainingTime = ref(90);
const timer = ref(null);

const startMessage = ref("");

onMounted(() => {
  if (process.client) {
    speakStartMessage(); // í˜ì´ì§€ ì§„ì… ì‹œ ìŒì„±ê³¼ í…ìŠ¤íŠ¸ ì•ˆë‚´
  }
});

const speakStartMessage = () => {
  const message = `AI ëª¨ì˜ ë©´ì ‘ì´ ê³§ ì‹œì‘ë©ë‹ˆë‹¤. ë©´ì ‘ ì§ˆë¬¸ì´ í™”ë©´ì— í‘œì‹œë˜ë©°, ìë™ìœ¼ë¡œ ìŒì„±ìœ¼ë¡œ ì½ì–´ë“œë¦½ë‹ˆë‹¤. 
  ì§ˆë¬¸ì„ ë‹¤ ë“¤ì€ ë’¤ì— ë§í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”. 
  ë§ˆì´í¬ì™€ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.`;

  // í™”ë©´ìš© ì•ˆë‚´ ë¬¸êµ¬ (HTML)
  startMessage.value = `
    <br>
    <strong>
      <span>AI ëª¨ì˜ ë©´ì ‘ì´ ê³§ ì‹œì‘ë©ë‹ˆë‹¤.</span><br>
      <span>ë©´ì ‘ ì§ˆë¬¸ì´ í™”ë©´ì— í‘œì‹œë˜ë©°, ìë™ìœ¼ë¡œ ìŒì„±ìœ¼ë¡œ ì½ì–´ë“œë¦½ë‹ˆë‹¤.</span><br>
      <span>ì§ˆë¬¸ì„ ë‹¤ ë“¤ì€ ë’¤, <mark>ë§í•˜ê¸° ë²„íŠ¼</mark>ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”.</span><br>
      <span>ë§ˆì´í¬ì™€ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.</span>
    </strong>
  `;

  // ìŒì„± ì•ˆë‚´
  const utterance = new SpeechSynthesisUtterance(message);
  utterance.lang = "ko-KR";
  utterance.rate = 1;
  utterance.pitch = 1;
  window.speechSynthesis.cancel();
  window.speechSynthesis.speak(utterance);
};

let recognition;
let synth = window.speechSynthesis;
let currentUtteance = null;

const formattedAIMessage = computed(() => {
  return currentAIMessage.value.replace(/([.?])/g, "$1<br>");
});

//ë‹¤ì‹œë“£ê¸°
const replayQuestion = () => {
  if (synth.speaking) synth.cancel();
  const utterance = new SpeechSynthesisUtterance(currentAIMessage.value);
  utterance.lang = "ko-KR";
  utterance.rate = 1;
  utterance.pitch = 5;
  setTimeout(() => synth.speak(utterance), 100);
};

// ë©´ì ‘ ë„ì¤‘ ë‚˜ê°€ë ¤ëŠ” ê²½ìš°
const handleBeforeUnload = (event) => {
  if (start.value) {
    event.preventDefault();
    event.returnValue = "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?";
    return "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?";
  }
};

const speakCurrentMessage = () => {
  clearInterval(timer.value); //ê¸°ì¡´ íƒ€ì´ë¨¸ ì •ì§€
  remainingTime.value = 90; //íƒ€ì´ë¨¸ ì´ˆê¸°í™”
  currentUtteance = new SpeechSynthesisUtterance(currentAIMessage.value);
  currentUtteance.lang = "ko-KR";
  currentUtteance.rate = 0.9;
  currentUtteance.pitch = 1.2;
  currentUtteance.onend = () => {
    startTimer();
  };
  synth.speak(currentUtteance);
};

const showStartMessage = () => {
  const plainMessage = startMessage
    .replace(/<br\s*\/?>/gi, "\n") 
    .replace(/<\/p>/gi, "\n")
    .replace(/<[^>]+>/g, "");
  currentUtteance = new SpeechSynthesisUtterance(plainMessage);
  currentUtteance.lang = "ko-KR";
  currentUtteance.rate = 0.9;
  currentUtteance.pitch = 1.2;
  currentUtteance.onend = () => {
    visible.value = false; // ì—¬ê¸°ì„œ ì „í™˜ë¨
    speakCurrentMessage();
  };
  synth.speak(currentUtteance);

  //IOS
  setTimeout(() => {
    if (visible.value) {
      visible.value = false;
      speakCurrentMessage();
    }
  }, 5000);
};

// íƒ€ì´ë¨¸
const startTimer = () => {
  clearInterval(timer.value);
  timer.value = setInterval(() => {
    if (remainingTime.value > 0) {
      remainingTime.value--;
    } else {
      clearInterval(timer.value);
      onAnswerComplete(); // ì‹œê°„ì´ ë‹¤ ë˜ë©´ ìë™ ì œì¶œ
    }
  }, 1000);
};

//STTì‹œì‘
const startSTT = () => {
  if (recognition && !recognizing.value) recognition.start();
};

const handleStartInterview = async () => {
  const info = JSON.parse(localStorage.getItem("interviewInfo") || "{}");
  if (!info.tech || !info.exp) {
    alert("ë©´ì ‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.");
    router.push("/ai-interview");
    return;
  }

  start.value = true;
  let techSkillNumberList = info.skills;
  console.log(`techSkillNumberList = ${techSkillNumberList}`);

  const res = await aiInterviewStore.requestCreateInterviewToDjango({
    userToken: localStorage.getItem("userToken"),
    jobCategory: info.tech,
    experienceLevel: info.exp,
    projectExperience: info.project,          
    academicBackground: info.academic,        
    // interviewTechStack: info.skills,
    interviewTechStack: techSkillNumberList
  });

  currentInterviewId.value = Number(res.interviewId);
  currentAIMessage.value = res.question;

  showStartMessage();
};

onMounted(() => {
  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) {
    alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
    return;
  }

  recognition = new SpeechRecognition();
  recognition.lang = "ko-KR";
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onstart = () => (recognizing.value = true);
  recognition.onend = () => (recognizing.value = false);
  recognition.onerror = () => (recognizing.value = false);
  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript;
    sttLog.value = transcript;
  };

  window.addEventListener("beforeunload", handleBeforeUnload);
});

// í˜ì´ì§€ ë‚˜ê°€ë©´ TTS ìº”ìŠ¬
onBeforeUnmount(() => {
  if (synth && synth.speaking) {
    synth.cancel();
  }
  localStorage.removeItem("interviewInfo");
  clearInterval(timer.value);
  window.removeEventListener("beforeunload", handleBeforeUnload);
});

//ë©´ì ‘ ë„ì¤‘ í˜ì´ì§€ ì´ë™
onBeforeRouteLeave((to, from, next) => {
  if (start.value) {
    const answer = window.confirm(
      "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?"
    );
    if (answer) {
      clearInterval(timer.value);
      next(); //ì´ë™ í—ˆìš©
    } else {
      next(false); //ì´ë™ ì·¨ì†Œ
    }
  } else {
    next();
  }
});

// ë‹µë³€
const onAnswerComplete = async () => {
  if (!sttLog.value.trim()) {
    alert("ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.");
    return;
  }
  const payload = {
    userToken: localStorage.getItem("userToken"),
    interviewId: currentInterviewId.value,
    questionId: currentQuestionId.value,
    answerText: sttLog.value,
  };

  //ì‚¬ìš©ì ì‘ë‹µ ì €ì¥
  await aiInterviewStore.requestCreateAnswerToDjango(payload);

  const followUp = await aiInterviewStore.requestFollowUpQuestionToDjango(
    payload
  );
  if (!followUp || !followUp.questions) {
    alert("ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    return;
  }
  console.log("ğŸ“© followUp ì‘ë‹µ:", followUp);
  currentQuestionId.value = followUp.questionId;
  currentAIMessage.value = followUp.questions;
  sttLog.value = "";
  speakCurrentMessage();
};

useHead({
  title: `AI ëª¨ì˜ë©´ì ‘ & ì¸ì„±ë©´ì ‘ | `,
  meta: [
    {
      name: "description",
      content: "AI ëª¨ì˜ë©´ì ‘, AI ì¸ì„±ë©´ì ‘ ğŸ¯AIVì—ì„œ í™•ì¸í•´ë³´ì„¸ìš”.",
    },
    {
      hid: "keywords",
      name: "keywords",
      content:
        "ëª¨ì˜ë©´ì ‘, ai ëª¨ì˜ë©´ì ‘, ì¸ì„±ë©´ì ‘, ai ì¸ì„±ë©´ì ‘, ì¸ì ì„± ê²€ì‚¬ ì¤€ë¹„, ai ì¸ì , ai ë©´ì ‘, aim ëª¨ì˜ë©´ì ‘, aim ai ëª¨ì˜ë©´ì ‘, AIV ëª¨ì˜ë©´ì ‘, AIV, AIV, AIV, AIV Sniper",
    },
  ],
});
</script>

<style scoped>
.interview-container {
  margin-top: 20%;
  border: 1px solid #333;
  padding: 16px;
  border-radius: 10px;
  width: 70%;
}

.input-area {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 20px;
  width: 50%;
  margin-bottom: 0;
}

.send-button {
  padding: 10px 12px;
  background-color: black;
  color: white;
  border: none;
  border-radius: 20px;
  cursor: pointer;
  font-size: 16px;
}

@keyframes loading-animation {
  0%,
  80%,
  100% {
    opacity: 0;
  }
  40% {
    opacity: 1;
  }
}

.context-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
.context-menu li {
  padding: 10px;
  cursor: pointer;
}
.context-menu li:hover {
  background-color: #f0f0f0;
}
</style>
